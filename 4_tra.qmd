# 4 Transparency (TRA)

This requirement is closely linked with the principle of explicability and encompasses transparency of elements relevant to an AI system: the data, the system and the business models.

## 4.1 Traceability

The data sets and the processes that yield the AI system’s decision, including those of data gathering and data labelling as well as the algorithms used, should be documented to the best possible standard to allow for traceability and an increase in transparency. This also applies to the decisions made by the AI system. This enables identification of the reasons why an AI-decision was erroneous which, in turn, could help prevent future mistakes. Traceability facilitates auditability as well as explainability.

### Requirement 41-1-TRA {#41-1-tra}

**Description:** ***\[Limitations and metadata\]*** are available to doctors in the app during emergencies.

| **Parameter**                | **Values**                                                                                                                                                                                                                 |
|---------------------------------------|---------------------------------|
| **Limitations and Metadata** | \- Data collection trail<br>- Data source<br>- How patient-specific input affected the predictions<br>- How model is calibrated and optimized, especially whether it has a tendency for false negatives or false positives |

<div style="background-color:#ff6900; padding:10px; border-radius:5px;">
**Validation**
</div>

**Owner**

-   WP 2 lead

::: {style="background-color:#e8daef; padding:10px; border-radius:5px;"}
**In Progress**
:::

## 4.2 Explainability

Explainability concerns the ability to explain both the technical processes of an AI system and the related human decisions (e.g. application areas of a system). Technical explainability requires that the decisions made by an AI system can be understood and traced by human beings. Moreover, trade-offs might have to be made between enhancing a system's explainability (which may reduce its accuracy) or increasing its accuracy (at the cost of explainability). Whenever an AI system has a significant impact on people’s lives, it should be possible to demand a suitable explanation of the AI system’s decision-making process. Such explanation should be timely and adapted to the expertise of the stakeholder concerned (e.g. layperson, regulator or researcher). In addition, explanations of the degree to which an AI system influences and shapes the organisational decision-making process, design choices of the system, and the rationale for deploying it, should be available (hence ensuring business model transparency).

### Requirement 42-1-TRA {#42-1-tra}

**Description:** The system is able to inform about parts of the input that led to a specific outcome.

<div style="background-color:#418f8c; padding:10px; border-radius:5px;">
**Development**
</div>
<div style="background-color:#006eff; padding:10px; border-radius:5px;">
**Testing**
</div>

**Owner**

-   WP 2 lead

::: {style="background-color: #e8daef; padding:10px; border-radius:5px;"}
**In Progress**
:::

### Requirement 42-2-TRA {#42-2-tra}

**Description:** % of ***\[explanations\]*** are communicated and defined in line with the ***\[constraints\]*** of the project.

| **Parameter**                     | **Values**                                                                                                                                                                                                                                  |
|---------------------------------------|---------------------------------|
| **Constraints**                   | \- Ethical values of the project<br>- Explainability regulations                                                                                                                                                                            |
| **Ethical values of the project** | Ethical framework                                                                                                                                                                                                                           |
| **Explanations**                  | How the AI model works; how the model has been trained; what data has been used; who participated in the study; how the data collected from prospective study is used and shared; how data collected from patients during use will be used? |
| **Explainability regulations**    | EU AI Act, GDPR, EU-MDR                                                                                                                                                                                                                     |

**Phases**: development, testing

**Owner**

-   WP 6 lead

::: {style="background-color: #abebc6; padding:10px; border-radius:5px;"}
Fulfilled
:::

### Requirement 42-3-TRA {#42-3-tra}

**Description:** % of ***\[explainability methods\]*** are applied in the tool and outputs are available to ***\[relevant users\]***.

| **Parameter**              | **Values**                                                                              |
|---------------------------------------|---------------------------------|
| **Explainability methods** | \- Explainability methods for tabular data<br>- Explainability methods for imaging data |
| **Relevant users**         | Medical personnel                                                                       |

**Phases**: development, testing

**Owner**

-   WP 2 lead

::: {style="background-color: #e8daef; padding:10px; border-radius:5px;"}
In Progress
:::

### Requirement 42-4-TRA {#42-4-tra}

**Description:** % of ***\[explainability methods\]*** applied in the tool are validated by ***\[metric\]***.

| **Parameter**              | **Values**                                                                                                                                                                     |
|---------------------------------------|---------------------------------|
| **Explainability methods** | \- Explainability methods for tabular and imaging data                                                                                                                         |
| **Metric**                 | \- Quantified scores<br>- Quantified validation by users                                                                                                                       |

<div style="background-color:#418f8c; padding:10px; border-radius:5px;">
**Development**
</div>
<div style="background-color:#006eff; padding:10px; border-radius:5px;">
**Testing**
</div>

**Owner**

-   WP 2 lead

::: {style="background-color: #e8daef; padding:10px; border-radius:5px;"}
**In Progress**
:::

## 4.3 Communication

AI systems should not represent themselves as humans to users; humans have the right to be informed that they are interacting with an AI system. This entails that AI systems must be identifiable as such. In addition, the option to decide against this interaction in favour of human interaction should be provided where needed to ensure compliance with fundamental rights. Beyond this, the AI system’s capabilities and limitations should be communicated to AI practitioners or end-users in a manner appropriate to the use case at hand. This could encompass communication of the AI system's level of accuracy, as well as its limitations.

### Requirement 43-1-TRA {#43-1-tra}

**Description:** ***\[Information\]*** for ***\[end-users\]*** are explained and ***\[communicated appropriately\]***, as well as translated by a science communicator when relevant.

| **Parameter**                  | **Values**                                                                                                                                                                              |                                                                                                                                                                                                                                                       |
|--------------------|---------------------------|-------------------------|
| *Questions*                    | *Patient, Patient family/caregiver*                                                                                                                                                     | *Medical professional*                                                                                                                                                                                                                                |
| **Information**                | \- Why are we using the tool?\<br\>- Why don't we know what the best treatment is?\<br\>- What are the results of the AI model? \<br\>- What do the results of the tool imply for them? | \- Why should I use this tool? \<br\>- When should I not use this tool? \<br\>- How do we know that this tool is successful? \<br\>- How does the model work? \<br\>- Which parameters/variables are input data? And which ones are deciding factors? |
| **End-users**                  | \- Patients<br>- Patient family/caregivers<br>- Medical professionals                                                                                                                   |                                                                                                                                                                                                                                                       |
| **Communicated appropriately** | Tailored to users in different countries                                                                                                                                                |                                                                                                                                                                                                                                                       |

**Phases**: development, testing, validation

**Owner**

-   WP 6 lead

::: {style="background-color:#e8daef; padding:10px; border-radius:5px;"}
In Progress
:::
