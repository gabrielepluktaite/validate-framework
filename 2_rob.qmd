# 2 Technical Robustness and Safety (ROB)

A crucial component of achieving Trustworthy AI is technical robustness, which is closely linked to the principle of prevention of harm. Technical robustness requires that AI systems be developed with a preventative approach to risks and in a manner such that they reliably behave as intended while minimising unintentional and unexpected harm, and preventing unacceptable harm. This should also apply to potential changes in their operating environment or the presence of other agents (human and artificial) that may interact with the system in an adversarial manner. In addition, the physical and mental integrity of humans should be ensured. 

## 2.1 Resilience to Attack and Safety

AI systems, like all software systems, should be protected against vulnerabilities that can allow them to be exploited by adversaries, e.g. hacking. Attacks may target the data (data poisoning), the model (model leakage) or the underlying infrastructure, both software and hardware. If an AI system is attacked, e.g. in adversarial attacks, the data as well as system behaviour can be changed, leading the system to make different decisions, or causing it to shut down altogether. Systems and data can also become corrupted by malicious intention or by exposure to unexpected situations. Insufficient security processes can also result in erroneous decisions or even physical harm. For AI systems to be considered secure, possible unintended applications of the AI system (e.g. dual-use applications) and potential abuse of the system by malicious actors should be taken into account, and steps should be taken to prevent and mitigate these.

### Requirement 21-1-ROB {#21-1-rob}

**Description:** Tool should follow ***\[relevant aspects of norms\]*** that are within our scope and resource limitations to prepare for compliance with the MDR by ***\[time point\]***.

***relevant aspects of norms:***

\- ISO norms relate to the standard MDR:

\- IEC 62366

\- IEC 62304

\- ISO 14971

\- ISO norms related to MDR and recent AI advancements:

\- ISO 13485

\- ISO/IEC 23894:2023

\- ISO/IEC 38507

***time point***: 

\- the end of the project\

**Phases**

\- development

\- testing

\- validation

**Owner**

\- WP 5 lead

**Stakeholders**

\- WP 2 (development)

\- WP 3 (design)

\- WP 5 (regulatory pathway to market)\

**Wish**

\- The stability of the accuracies and performance for ***when there are missing input data points*** of the tool is analyzed or monitored, available ***by the start of the validation phase***. 

\- Tool should follow ***relevant aspects of ISO norms related to the MDR and recent AI advancements: ISO 13485; ISO/IEC 23894:2023; ISO/IEC 38507***that are within our scope and resource limitations to prepare for compliance with the MDR by ***the end of the project**.*

### Requirement 21-2-ROB {#21-2-rob}

**Description:** Tool should follow ***\[relevant guidelines on cyber security\]*** that are within our scope and resource limitations to prepare for compliance with the MDR by ***\[time point\]***.

***relevant guidelines on cyber security:***

\- to be defined, needs to be researched by Owner.

***time point***: 

\- the end of the project

**Phases**

\- development

\- testing

\- validation

**Owner**

\- WP 5 lead

**Stakeholders**

\- WP 2 (development)

\- WP 3 (design)

\- WP 5 (regulatory pathway to market)\

**Wish**

\- Tool should follow ***\[relevant guidelines on cyber security\]*** that are within our scope and resource limitations to prepare for compliance with the MDR by ***the end of the project***.

## 2.2 Fallback plan and general safety

AI systems should have safeguards that enable a fallback plan in case of problems. This can mean that AI systems switch from a statistical to rule-based procedure, or that they ask for a human operator before continuing their action. It must be ensured that the system will do what it is supposed to do without harming living beings or the environment. This includes the minimisation of unintended consequences and errors. In addition, processes to clarify and assess potential risks associated with the use of AI systems, across various application areas, should be established. The level of safety measures required depends on the magnitude of the risk posed by an AI system, which in turn depends on the system’s capabilities. Where it can be foreseen that the development process or the system itself will pose particularly high risks, it is crucial for safety measures to be developed and tested proactively. 

### Requirement 22-1-ROB {#22-1-rob}

**Description:** A risk assessment following relevant aspects of ***\[risk management norms\]*** will be done by ***\[time point\]***.

***risk management norms:***

\- ISO 14971

\- ISO 23894:2023

***time point***: 

\- when intended purpose is defined

\- at the end of the project\

**Phases**

\- development

\- testing

\- validation

**Owner**

\- WP 5 lead

**Stakeholders**

\- WP 2 (development)

\- WP 3 (design)

\- WP 5 (regulatory pathway to market)\

**Goal**

\- A risk assessment following relevant aspects of ***ISO 14971*** will be done by ***at the end of the project**.*

**Wish**

\- A risk assessment following relevant aspects of ***ISO 23894:2023*** will be done by ***when intended purpose is defined**.*

## 2.3 Accuracy

Accuracy pertains to an AI system’s ability to make correct judgements, for example to correctly classify information into the proper categories, or its ability to make correct predictions, recommendations, or decisions based on data or models. An explicit and well-formed development and evaluation process can support, mitigate and correct unintended risks from inaccurate predictions. When occasional inaccurate predictions cannot be avoided, it is important that the system can indicate how likely these errors are. A high level of accuracy is especially crucial in situations where the AI system directly affects human lives. 

### Requirement 23-1-ROB {#23-1-rob}

**Description:** Validity will be measured by doing a randomized clinical trial (RCT) to examine whether at least ***\[ratio\]*** of ***\[RCT study size\]*** patients whose doctors use the tool have a significantly improved Modified Ranking Scale 90 (MRS 90) compared to control group at ***\[time point\].***

***ratio:***

\- will be determined at the end of the prospective study

***RCT study size:***

\- number will be determined later by estimating the effect size

***time point***: 

\- after the project\

**Phases**

\- validation

**Owner**

\- WP 4 lead

**Stakeholders**

\- WP 4 (clinical validation)\

**Wish**

\- Validity will be measured by doing a randomized clinical trial (RCT) to examine whetherat least ***\[ratio\]*** of ***number determined by estimated effect size patients*** whose doctors use the tool have a significantly improved MRS 90 compared to control group at ***after the project*****.**

### Requirement 23-2-ROB {#23-2-rob}

**Description:** Accuracy will be measured by ***\[time point\]*** by doing a prospective shadowing study to examine whether in at least ***\[threshold\]*** of the cases, the predictions of the prototype are similar to the actual 3 months mRS according to the actual administered treatment.

***threshold:***

\- 90%

***time point***: 

\- the end of the project\

**Phases**

\- validation

**Owner**

\- WP 4 lead

**Stakeholders**

\- WP 4 (clinical validation)\

**Goal**

\- Accuracy will be measured by ***the end of the project*** by doing a prospective shadowing study to examine whether in at least ***90%*** of the cases, the predictions of the prototype are similar to the actual 3 months mRS according to the actual administered treatment

## 2.4 Reliability and Reproducibility

It is critical that the results of AI systems are reproducible, as well as reliable. A reliable AI system is one that works properly with a range of inputs and in a range of situations. This is needed to scrutinise an AI system and to prevent unintended harms. Reproducibility describes whether an AI experiment exhibits the same behaviour when repeated under the same conditions. This enables scientists and policy makers to accurately describe what AI systems do. Replication files can facilitate the process of testing and reproducing behaviours. 

### Requirement 24-1-ROB {#24-1-rob}

**Description:** Tool reliably provides no significantly different performance for ***\[contexts\]*** at ***\[time point\].***

***contexts:***

\- edge-cases

\- differing local standards of care

\- non-western patient minorities

***time point***:

\- at the end of the project\

**Phases**

\- development

\- testing

\- validation

**Owner**

\- WP 2 lead

**Stakeholders**

\- WP 2 (development)

\- WP 3 (design)

\- WP 4 (clinical validation)\

**Goal**

\- Tool reliably provides no significantly different performance for ***edge-cases*** ***at the end of the project***.

\- Tool reliably provides no significantly different performance for ***differing local standards of care*** ***at the end of the project***.

\- Tool reliably provides no significantly different performance for ***non-western patient minorities at the end of the project***.

### Requirement 24-2-ROB {#24-2-rob}

**Description:** The stability of the accuracies and performance for ***\[different risk areas\]*** of the tool is analyzed or monitored, available by ***\[time point\].***

***different risk areas:*** \[from 35-ROB\]

\- edge-cases

\- differing local standards of care

\- non-western patient minorities

\- when there are missing input data points

\- for sub-groups mentioned in 61-DIV

***time point***: 

\- by the start of the validation phase. *See “How the requirements are organized” on page 7.*\

**Phases**

\- development

\- testing

\- validation

**Owner**

\- WP 2 lead

**Stakeholders**

\- WP 2 (development)

\- WP 3 (design)

\- WP 4 (clinical validation)\

**Tolerable**

\- The stability of the accuracies and performance for ***when there are missing input data points*** of the tool is analyzed or monitored, available ***by the start of the validation phase*****.**

**Goal** 

\- The stability of the accuracies and performance for ***edge-cases, differing local standards of care, non-western patient minorities*** of the tool is analyzed or monitored, available ***by the validation phase*****.**

\- The stability of the accuracies and performance for ***sub-groups mentioned in 61-DIV*** of the tool is analyzed or monitored, available ***by the validation phase***.

### Requirement 24-3-ROB {#24-3-rob}

**Description:** The tool has a defined intended purpose following the MDR ***\[time point\]***.

***time point***: 

\- as part of the prototype development\

**Phases**

\- development

\- testing

**Owner**

\- WP 3 lead

**Stakeholders**

\- WP 2 (development)

\- WP 4 (clinical validation)

\- WP 5 (regulations)\

**Tolerable**

\- The tool has a defined intended purpose following the MDR ***as part of the prototype development**.*
