# 2 Technical Robustness and Safety (ROB)

A crucial component of achieving Trustworthy AI is technical robustness, which is closely linked to the principle of prevention of harm. Technical robustness requires that AI systems be developed with a preventative approach to risks and in a manner such that they reliably behave as intended while minimising unintentional and unexpected harm, and preventing unacceptable harm. This should also apply to potential changes in their operating environment or the presence of other agents (human and artificial) that may interact with the system in an adversarial manner. In addition, the physical and mental integrity of humans should be ensured. 

## 2.1 Resilience to Attack and Safety

AI systems, like all software systems, should be protected against vulnerabilities that can allow them to be exploited by adversaries, e.g. hacking. Attacks may target the data (data poisoning), the model (model leakage) or the underlying infrastructure, both software and hardware. If an AI system is attacked, e.g. in adversarial attacks, the data as well as system behaviour can be changed, leading the system to make different decisions, or causing it to shut down altogether. Systems and data can also become corrupted by malicious intention or by exposure to unexpected situations. Insufficient security processes can also result in erroneous decisions or even physical harm. For AI systems to be considered secure, possible unintended applications of the AI system (e.g. dual-use applications) and potential abuse of the system by malicious actors should be taken into account, and steps should be taken to prevent and mitigate these.

### Requirement 21-1-ROB {#21-1-rob}

**Description:** Tool should follow ***\[relevant aspects of norms\]*** that are within our scope and resource limitations to prepare for compliance with the MDR.

| **Parameter**                 | **Values**                                                                                                                                                                                                 |
|-------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Relevant Aspects of Norms** | ISO norms related to the standard MDR:<br>- IEC 62366<br>- IEC 62304<br>- ISO 14971<br><br> ISO norms related to MDR and recent AI advancements:<br>- ISO 13485<br>- ISO/IEC 23894:2023<br>- ISO/IEC 38507 |                                                                                                                

<div style="background-color:#ff6900; padding:10px; border-radius:5px;">
**Validation**
</div>

**Owner**

-   WP 5 lead

::: {style="background-color:#e6f7ff; padding:10px; border-radius:5px;"}
**To Be Done**
<br>**Note**: a document listing all relevant ISO norms for VALIDATE is under preparation..
:::

### Requirement 21-2-ROB {#21-2-rob}

**Description:** Tool should follow ***\[relevant guidelines on cyber security\]*** that are within our scope and resource limitations to prepare for compliance with the MDR.

| **Parameter**                             | **Values**                                      |
|-------------------------------------------|-------------------------------------------------|
| **Relevant Guidelines on Cyber Security** | To be defined, needs to be researched by Owner. |


<div style="background-color:#006eff; padding:10px; border-radius:5px;">
**Testing**
</div>
<div style="background-color:#ff6900; padding:10px; border-radius:5px;">
**Validation**
</div>

**Owner**

-   WP 5 lead

::: {style="background-color:#e6f7ff; padding:10px; border-radius:5px;"}
**To Be Done**
<br>**Note**: no identified barriers for market entry, but considered high-level and inappropriate for VALIDATE’s outputs.
:::

## 2.2 Fallback plan and general safety

AI systems should have safeguards that enable a fallback plan in case of problems. This can mean that AI systems switch from a statistical to rule-based procedure, or that they ask for a human operator before continuing their action. It must be ensured that the system will do what it is supposed to do without harming living beings or the environment. This includes the minimisation of unintended consequences and errors. In addition, processes to clarify and assess potential risks associated with the use of AI systems, across various application areas, should be established. The level of safety measures required depends on the magnitude of the risk posed by an AI system, which in turn depends on the system’s capabilities. Where it can be foreseen that the development process or the system itself will pose particularly high risks, it is crucial for safety measures to be developed and tested proactively. 

### Requirement 22-1-ROB {#22-1-rob}

**Description:** A risk assessment following relevant aspects of ***\[risk management norms\]*** will be done.

| **Parameter**             | **Values**                                                         |
|---------------------------|--------------------------------------------------------------------|
| **Risk Management Norms** | \- ISO 14971<br>- ISO 23894:2023                                   |


<div style="background-color:#ff6900; padding:10px; border-radius:5px;">
**Validation**
</div>

**Owner**

-   WP 5 lead

::: {style="background-color:#e8daef; padding:10px; border-radius:5px;"}
**In progress**
<br>**Note**: continued iteration of intended use purpose is ongoing; no final intended use purpose is yet defined.
:::

## 2.3 Accuracy

Accuracy pertains to an AI system’s ability to make correct judgements, for example to correctly classify information into the proper categories, or its ability to make correct predictions, recommendations, or decisions based on data or models. An explicit and well-formed development and evaluation process can support, mitigate and correct unintended risks from inaccurate predictions. When occasional inaccurate predictions cannot be avoided, it is important that the system can indicate how likely these errors are. A high level of accuracy is especially crucial in situations where the AI system directly affects human lives. 

### Requirement 23-1-ROB {#23-1-rob}

**Description:** Accuracy will be measured by doing a prospective shadowing study to examine whether in at least ***\[threshold\]*** of the cases, the predictions of the prototype are similar to the actual 3 months mRS according to the actual administered treatment.

| **Parameter**  | **Values**             |
|----------------|------------------------|
| **Threshold**  | 90%                    |

<div style="background-color:#ff6900; padding:10px; border-radius:5px;">
**Validation**
</div>

**Owner**

-   WP 4 lead

::: {style="background-color:#e8daef; padding:10px; border-radius:5px;"}
**In progress**
<br>**Note**: 50 patients have been recruited for the study and evaluation for the accuracy of the VALIDATE tool will begin in Spring 2026.
:::

### Requirement 23-2-ROB {#23-2-rob}

**Description:** Validity will be measured by doing a randomized clinical trial (RCT) to examine whether at least ***\[ratio\]*** of ***\[RCT study size\]*** patients whose doctors use the tool have a significantly improved Modified Ranking Scale 90 (MRS 90) compared to control group.

| **Parameter**      | **Values**                                                    |
|--------------------|---------------------------------------------------------------|
| **Ratio**          | Will be determined at the end of the prospective study        |
| **RCT Study Size** | Number will be determined later by estimating the effect size |

<div style="background-color:#ff6900; padding:10px; border-radius:5px;">
**Validation**
</div>

**Owner**

-   WP 4 lead

::: {style="background-color:#e6f7ff; padding:10px; border-radius:5px;"}
**To Be Done**
<br>**Note**: RCT will likely not happen within the scope of the VALIDATE project but results of prospective shadowing study will inform design of an RCT.
:::

## 2.4 Reliability and Reproducibility

It is critical that the results of AI systems are reproducible, as well as reliable. A reliable AI system is one that works properly with a range of inputs and in a range of situations. This is needed to scrutinise an AI system and to prevent unintended harms. Reproducibility describes whether an AI experiment exhibits the same behaviour when repeated under the same conditions. This enables scientists and policy makers to accurately describe what AI systems do. Replication files can facilitate the process of testing and reproducing behaviours. 

### Requirement 24-1-ROB {#24-1-rob}

**Description:** The tool’s performance and accuracy are monitored and analysed, ensuring no significant differences in performance across ***\[risk areas/contexts\]***.

+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| **Parameter**  | **Values**                                                                                                                                                                                                              |
+================+=========================================================================================================================================================================================================================+
| **Contexts**   | - Edge-cases<br>- Differing local standards of care<br>- Non-western patient minorities<br>- Missing input data points<br>-Sub-groups mentioned in 51-1-DIV (Age, sex/gender, ethnicity/race, geographic location) |
+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

<div style="background-color:#ff6900; padding:10px; border-radius:5px;">
**Validation**
</div>

**Owner**

-   WP 2 lead

::: {style="background-color:#e8daef; padding:10px; border-radius:5px;"}
**In Progress**
<br>**Note**: Initial analysis on missing data scenarios has been done in D2.2 pages 54-9. More work on missingness will be done in a retrospective paper whose results will be included in D2.3. Thus, D2.2 and D2.3 will be added as artefacts.
:::

### Requirement 24-2-ROB {#24-2-rob}

**Description:** The tool has a defined intended purpose following the MDR.

<div style="background-color:#418f8c; padding:10px; border-radius:5px;">
**Development**
</div>
<div style="background-color:#006eff; padding:10px; border-radius:5px;">
**Testing**
</div>

**Owner**

-   WP 3 lead

::: {style="background-color:#e8daef; padding:10px; border-radius:5px;"}
**In Progress**
<br>**Note**: Mural board link and D3.5 detail the intended purpose of the tool and should be added here as artefacts.
:::
