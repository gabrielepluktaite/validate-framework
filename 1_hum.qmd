# Human Agency and Oversight (HUM)

AI systems should support human autonomy and decision-making, as prescribed by the principle of respect for human autonomy. This requires that AI systems should both act as enablers to a democratic, flourishing and equitable society by supporting the user’s agency and foster fundamental rights and allow for human oversight.

## Fundamental rights

Like many technologies, AI systems can equally enable and hamper fundamental rights. They can benefit people for instance by helping them track their personal data, or by increasing the accessibility of education, hence supporting their right to education. However, given the reach and capacity of AI systems, they can also negatively affect fundamental rights. In situations where such risks exist, a fundamental rights impact assessment should be undertaken. This should be done prior to the system’s development and include an evaluation of whether those risks can be reduced or justified as necessary in a democratic society in order to respect the rights and freedoms of others. Moreover, mechanisms should be put into place to receive external feedback regarding AI systems that potentially infringe on fundamental rights.

***None of the identified requirements could be mapped to this category. Other than the requirements addressed in related sections such as privacy, we believe that our tool does not influence fundamental rights.***

## Human Agency

Users should be able to make informed autonomous decisions regarding AI systems. They should be given the knowledge and tools to comprehend and interact with AI systems to a satisfactory degree and, where possible, be enabled to reasonably self-assess or challenge the system. AI systems should support individuals in making better, more informed choices in accordance with their goals. AI systems can sometimes be deployed to shape and influence human behaviour through mechanisms that may be difficult to detect, since they may harness sub-conscious processes, including various forms of unfair manipulation, deception, herding and conditioning, all of which may threaten individual autonomy. The overall principle of user autonomy must be central to the system’s functionality. Key to this is the right not to be subject to a decision based solely on automated processing when this produces legal effects on users or similarly significantly affects them.

### Requirement 12-1-HUM

**Description:** In the events where there is a clear conflict between the predictions of the tool and the medical opinion of the doctor, a process protocol for epistemic authority dilemmas customized for ***physician expertise level*** can be followed. Available by ***time point***.

***physician expertise level***: 
\- beginner
\- intermediate
\- expert

***time point***:\
- project end

**Owner**\
- WP1 lead

**Stakeholders**

\- WP 1 (ethics)

\- WP 3 (design)

\- WP 4 (clinical validation)

\- Other: medical staff

**Tolerable**

\- In the events where there is a clear conflict between the predictions of the tool and the medical opinion of the doctor, a process protocol for epistemic authority dilemmas customized for ***beginner; intermediate; expert*** can be followed. Available by ***project end***.

### Requirement 13-1-HUM

**Description:** Tool is designed with ***\[capability needed\]*** to enable a Human in Command (HIC) governance structure. This is implemented by ***\[time point\].***

***capability needed:***

\- capability to oversee the overall activity of the AI system;

\- ability to decide whether, when and how to use the system in any particular situation;

\- established levels of human discretion during the use of the system where necessary;

\- ability to override a decision made by a system

***time point***:\ 
- project end

**Owner**\
- WP1 lead

**Stakeholders**

\- WP 1 (ethics)

\- WP 3 (design)

\- WP 4 (clinical validation)

**Tolerable**

\- Tool is designed with ***capability to oversee the overall activity of the AI system*** to enable a HIC governance structure. This is implemented ***by the end of the project***.

**Goal** 

\- Tool is designed with ***ability to decide whether, when and how to use the system in any particular situation*** to enable a HIC governance structure. This is implemented ***by the end of the project***.

\- Tool is designed with ***established levels of human discretion during the use of the system where necessary*** to enable a HIC governance structure. This is implemented ***by the end of the project***.

\- Tool is designed with ***ability to override a decision made by a system*** to enable a HIC governance structure. This is implemented ***by the end of the project***.
